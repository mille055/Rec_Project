import warnings
warnings.filterwarnings('ignore')
import streamlit as st
import os
import nltk


# Download NLTK packages as Streamlit cloud VM does not have them
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('stopwords')


# Define constants
_CURRENT_DIR = os.path.dirname(os.path.realpath(__file__))
_BANNER = 'assets/podcast_neon_banner.jpeg'


if __name__ == '__main__':
    st.set_page_config(page_title='Podcast Recommender üéôÔ∏è')
    st.title('Podcast Recommender üéôÔ∏è')
    st.image(os.path.join(_CURRENT_DIR, _BANNER))
    st.markdown('This web app demonstrates different recommendation systems for podcasts based on keyword similarity and content filtering.')
    
    st.markdown("### Data")
    st.write("Data was scraped from the iTunes podcast website, and includes podcast title, genre, producer, description, episode description, number of ratings, average rating, user rating, image url, and itunes id. The dataset comprises 46,711 user-rating pairs corresponding to 3,936 unique podcasts.")
    
    st.markdown("#### Content-based Filtering")
    st.markdown('<div style="text-align: justify;">Content-based filtering was performed on some of the podcast features. In particular, text embeddings of the "genre", "description", and "episode_descriptions" columns were generated to obtain similarity matrices using cosine similarity. The embeddings were generated using a pre-trained sentence transformers model called Siamese-BERT from HuggingFace (model "all-MiniLM-L6-v2"). Different combinations of the features (embedded text from the 3 columns) were investigated and the best results were obtained with the combination of the genre and overall podcast description.</div>', unsafe_allow_html=True)
    
    st.markdown("#### Keyword Similarity")
    st.markdown('<div style="text-align: justify;">A non-machine learning approach based on Term Frequency and Inverse Document Frequency (TF-IDF) weighting was performed on the description feature of the podcasts. In particular, a vocabulary of the description was first generated by removing common stop words in English and this vocabulary is then fitted to a TF-IDF vectorizer to create a TF-IDF weighted document matrix. Keywords of interest are turned into a vector and being compared to each document in the TF-IDF matrix based on cosine similarity. The most similar results are returned as recommendations. Decent recommendations are observed if keywords of interest are not super rare or archaic.</div>', unsafe_allow_html=True)
    
    st.markdown("#### Demo")
    st.markdown("Click on the pages in the menu to try out the recommendation systems.")